{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Raw Data from CSVs\n",
    "\n",
    "Subreddit data is split by subreddit, where each CSV file has information \n",
    "about 1000 posts from a subreddit. We unpack data and store it according to the\n",
    "subreddit it came from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "subreddit_file = open('archive/50_subreddits_list.csv', mode='r', encoding='utf-8-sig')\n",
    "subreddits = {}\n",
    "for line in subreddit_file.readlines():\n",
    "  subreddit = line.rstrip(\"\\n\").lower()\n",
    "  df = pd.read_csv(f'archive/{subreddit}.csv')\n",
    "  subreddits[subreddit] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Title and Text from DataFrames\n",
    "\n",
    "Our classifier only works based on the title and main body of reddit posts,\n",
    "so we extract this information here. Our model doesn't distinguish between text\n",
    "in either portion since different subreddits have different rules about text\n",
    "in titles or bodies, so we store this as a single string of both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      'Dragon Ball' Creator Akira Toryiyama Has Pass...\n",
       "1        Kaguya-sama: Love Is War - Season 3 announced! \n",
       "2                         Aqua in yoga pants | Konosuba \n",
       "3                     This is not a Cigarette [Gintama] \n",
       "4         The Devil is a Part-Timer Season 2 Announced! \n",
       "                             ...                        \n",
       "991    Mob Psycho 100 Season 2 - Episode 5 discussion...\n",
       "992    Never thought in a million years I’d come acro...\n",
       "993    I seriously hate Sundays [Engaged to the Unide...\n",
       "994                \"Spy Classroom\" New Character Visual \n",
       "995    Hayasaka Ai in Spy Suit from \"Kaguya: Love is ...\n",
       "Length: 996, dtype: object"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subreddit_bodies = {}\n",
    "for subreddit in subreddits:\n",
    "  df = subreddits[subreddit]\n",
    "  df['title'] = df['title'].fillna('')\n",
    "  df['body'] = df['body'].fillna('')\n",
    "  subreddit_bodies[subreddit] = df['title'] + \" \" + df['body'] \n",
    "\n",
    "subreddit_bodies['anime']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Links\n",
    "Our dataset includes links that people included in posts, which likely won't be\n",
    "informative in classifying posts. We remove links here using regex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      I visited North Korea recently, these are some...\n",
       "1      Taken with a phone out of my hotel window in V...\n",
       "2      Taking a ride on the Bernina Express through t...\n",
       "3      Wife and I hate big social events and love tra...\n",
       "4      The exact moment I took a step too close to th...\n",
       "                             ...                        \n",
       "992    Sisteron- France. Beautiful place we had a cof...\n",
       "993    Croatia, probably the most beautiful country i...\n",
       "994    Michelangelo's David is great, but pieta is on...\n",
       "995    If you don't mind a little dust and grit and y...\n",
       "996    I’d never realized how beautiful Montenegro wa...\n",
       "Length: 997, dtype: object"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re # Regex Library\n",
    "\n",
    "def removeLinks(txt):\n",
    "  return re.sub(\"(www|http:|https:)+[^\\s]+\", \"\", txt)\n",
    "\n",
    "no_links = {}\n",
    "for subreddit in subreddit_bodies:\n",
    "  data = subreddit_bodies[subreddit]\n",
    "  no_links[subreddit] = data.map(lambda txt: removeLinks(txt))\n",
    "\n",
    "no_links['travel']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Words\n",
    "\n",
    "Since reddit posts are often formatted as prose with various punctuation marks,\n",
    "we split words into word tokens to focus on the words in each post instead of\n",
    "punctiation (i.e. 'wow!' should be treated the same as 'wow').\n",
    "\n",
    "We also format words here to limit variability caused by the context of each word, such as:\n",
    "- Turning each word to lowercase (i.e. 'WOW' should be treated the same as 'wow')\n",
    "- Replacing the special unicode character ’ with ' since a number of posts included it (i.e. \"I’d\" vs \"I'd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      [new, discovery, mode, turns, video, game, ass...\n",
       "1      [we, are, not, here, to, help, you, with, your...\n",
       "2      [a, 1776, excerpt, from, john, adam's, diary, ...\n",
       "3      [famous, viking, warrior, burial, revealed, to...\n",
       "4      [3, 000, year, old, underwater, castle, discov...\n",
       "                             ...                        \n",
       "987    [dna, study, has, now, provided, support, for,...\n",
       "988    [stonehenge, megalith, came, from, scotland, n...\n",
       "989    [french, resistance, man, breaks, silence, ove...\n",
       "990    [holy, grail, of, shipwrecks', to, be, raised,...\n",
       "991    [emily, wilson's, new, translation, of, the, i...\n",
       "Length: 992, dtype: object"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "tokenizer = nltk.RegexpTokenizer(\n",
    "  pattern=r\"[\\w']+\", # Only match words as tokens (coarsely, \\w + apostrophes)\n",
    "  gaps=False,\n",
    "  discard_empty=True # Remove empty tokens caused by markdown content\n",
    ")\n",
    "\n",
    "def tokenize(txt):\n",
    "  return tokenizer.tokenize(txt.replace(\"’\", \"'\").lower())\n",
    "\n",
    "tokenized_subreddits = {}\n",
    "for subreddit in no_links:\n",
    "  data = no_links[subreddit]\n",
    "  tokenized_subreddits[subreddit] = data.map(lambda txt: tokenize(txt)) \n",
    "\n",
    "tokenized_subreddits['history']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'funny', 1: 'askreddit', 2: 'gaming', 3: 'aww', 4: 'music', 5: 'pics', 6: 'science', 7: 'worldnews', 8: 'movies', 9: 'todayilearned', 10: 'videos', 11: 'news', 12: 'showerthoughts', 13: 'earthporn', 14: 'gifs', 15: 'jokes', 16: 'mildlyinteresting', 17: 'iama', 18: 'books', 19: 'lifeprotips', 20: 'diy', 21: 'sports', 22: 'nottheonion', 23: 'food', 24: 'explainlikeimfive', 25: 'space', 26: 'history', 27: 'art', 28: 'internetisbeautiful', 29: 'documentaries', 30: 'tifu', 31: 'askscience', 32: 'dataisbeautiful', 33: 'upliftingnews', 34: 'futurology', 35: 'writingprompts', 36: 'getmotivated', 37: 'oldschoolcool', 38: 'creepy', 39: 'listentothis', 40: 'technology', 41: 'personalfinance', 42: 'interestingasfuck', 43: 'wholesomememes', 44: 'relationship_advice', 45: 'memes', 46: 'travel', 47: 'television', 48: 'anime', 49: 'nostupidquestions'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>my cab driver tonight was so excited to share ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>guardians of the front page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gas station worker takes precautionary measure...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the conversation my son and i will have on chr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the denver broncos have the entire town of sou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49261</th>\n",
       "      <td>how come no one has invented a foot pedal for ...</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49262</th>\n",
       "      <td>why are trans people talked about so much desp...</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49263</th>\n",
       "      <td>did your penis ever fall asleep like your legs...</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49264</th>\n",
       "      <td>someone stole my bike i tracked it to its loca...</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49265</th>\n",
       "      <td>why are cops allowed to be fat but seriously h...</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49266 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text subreddit\n",
       "0      my cab driver tonight was so excited to share ...         0\n",
       "1                            guardians of the front page         0\n",
       "2      gas station worker takes precautionary measure...         0\n",
       "3      the conversation my son and i will have on chr...         0\n",
       "4      the denver broncos have the entire town of sou...         0\n",
       "...                                                  ...       ...\n",
       "49261  how come no one has invented a foot pedal for ...        49\n",
       "49262  why are trans people talked about so much desp...        49\n",
       "49263  did your penis ever fall asleep like your legs...        49\n",
       "49264  someone stole my bike i tracked it to its loca...        49\n",
       "49265  why are cops allowed to be fat but seriously h...        49\n",
       "\n",
       "[49266 rows x 2 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bring tokens back together as data\n",
    "def joinTokens(tokens):\n",
    "  return ' '.join(tokens)\n",
    "\n",
    "subreddit_classes = {}\n",
    "subreddit_df = pd.DataFrame(columns=['text', 'subreddit'])\n",
    "\n",
    "# We label classes incrementing from 0 so class information can later be\n",
    "# determined by indexing into arrays\n",
    "next_class = 0\n",
    "for subreddit in tokenized_subreddits:\n",
    "  subreddit_classes[next_class] = subreddit\n",
    "  data = pd.DataFrame()\n",
    "  data['text'] = tokenized_subreddits[subreddit].map(lambda tokens: joinTokens(tokens))\n",
    "  data['subreddit'] = next_class\n",
    "  subreddit_df = pd.concat([subreddit_df, data], ignore_index=True)\n",
    "  next_class += 1\n",
    "\n",
    "subreddit_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = subreddit_df['text']\n",
    "y = subreddit_df['subreddit']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=True)\n",
    "X_train = X_train.astype('str')\n",
    "X_test = X_test.astype('str')\n",
    "y_train = y_train.astype('int')\n",
    "y_test = y_test.astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Pipeline\n",
    "\n",
    "Scikit Learn allows you to string multiple functions together to process data\n",
    "and train model as is done here. The steps our model takes are\n",
    "\n",
    "- CountVectorizer: Takes the preprocessed post strings and counts word occurences\n",
    "- TfidfTransformer: Weights importance of words based on number of occurences across posts\n",
    "- SGDClassifier: Stochastic Gradient Descent to classify subreddits\n",
    "\n",
    "This pipeline is inspired by a Scikit Learn tutorial on text classification at [https://scikit-learn.org/1.4/tutorial/text_analytics/working_with_text_data.html](https://scikit-learn.org/1.4/tutorial/text_analytics/working_with_text_data.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "reddit_classifer = Pipeline([\n",
    "  ('cv', CountVectorizer()),\n",
    "  ('tfidf', TfidfTransformer()),\n",
    "  ('sgd', SGDClassifier()),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search\n",
    "\n",
    "Each step in the pipeline has parameters to tune how the model runs; Scikit Learn\n",
    "goes through each combination of parameters and returns the best combination of\n",
    "parameters to maximize accuracy. We chose to search over:\n",
    "\n",
    "- The size of \"word\" features to consider (1-word features or 1-2 word features)\n",
    "- The minimum word frequency to consider for features (since particularly uncommon words may not be insightful)\n",
    "- The maximum number of features to consider (since the least impactful features may not be insightful)\n",
    "- SGD loss function (either Log Loss or Modified Huber since these are the only two that can provide the class probabilities we show)\n",
    "\n",
    "Note: While accuracy is not the best test of model efficacy as discussed in class,\n",
    "here we felt the default is sufficient since with 50 roughly equally-represented\n",
    "classes a dummy classifier can't achieve above a ~2% accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5862\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cv__max_df': 0.5,\n",
       " 'cv__min_df': 1,\n",
       " 'cv__ngram_range': (1, 2),\n",
       " 'sgd__loss': 'modified_huber'}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grid_search = GridSearchCV(reddit_classifer, {\n",
    "  'cv__ngram_range': [(1, 1), (1, 2)],\n",
    "  'cv__min_df': [1, 3, 5],\n",
    "  'cv__max_features': [10000, 100000, None],\n",
    "  'sgd__loss': ['log_loss', 'modified_huber']\n",
    "}, n_jobs=8)\n",
    "grid_search.fit(X_train[:10000], y_train[:10000]) # Subset of Data for efficiency\n",
    "\n",
    "print(grid_search.best_score_)\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model\n",
    "\n",
    "Using the GridSearch parameters above, we train our pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-13 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-13 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-13 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-13 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-13 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-13 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-13 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-13 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-13 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-13 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-13 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-13 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-13 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-13 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-13 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-13 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-13 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-13 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-13 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-13 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-13 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-13 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-13 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-13 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-13 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-13 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-13 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-13 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-13 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-13 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-13 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-13 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-13 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-13 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-13 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-13 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-13 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-13 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-13 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-13 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-13 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-13 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-13\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;cv&#x27;, CountVectorizer(ngram_range=(1, 2))),\n",
       "                (&#x27;tfidf&#x27;, TfidfTransformer()),\n",
       "                (&#x27;sgd&#x27;, SGDClassifier(loss=&#x27;modified_huber&#x27;))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-45\" type=\"checkbox\" ><label for=\"sk-estimator-id-45\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;Pipeline<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;cv&#x27;, CountVectorizer(ngram_range=(1, 2))),\n",
       "                (&#x27;tfidf&#x27;, TfidfTransformer()),\n",
       "                (&#x27;sgd&#x27;, SGDClassifier(loss=&#x27;modified_huber&#x27;))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-46\" type=\"checkbox\" ><label for=\"sk-estimator-id-46\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;CountVectorizer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\">?<span>Documentation for CountVectorizer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>CountVectorizer(ngram_range=(1, 2))</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-47\" type=\"checkbox\" ><label for=\"sk-estimator-id-47\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;TfidfTransformer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html\">?<span>Documentation for TfidfTransformer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>TfidfTransformer()</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-48\" type=\"checkbox\" ><label for=\"sk-estimator-id-48\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;SGDClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.SGDClassifier.html\">?<span>Documentation for SGDClassifier</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>SGDClassifier(loss=&#x27;modified_huber&#x27;)</pre></div> </div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('cv', CountVectorizer(ngram_range=(1, 2))),\n",
       "                ('tfidf', TfidfTransformer()),\n",
       "                ('sgd', SGDClassifier(loss='modified_huber'))])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_classifer = Pipeline([\n",
    "  ('cv', CountVectorizer(ngram_range=(1,2))),\n",
    "  ('tfidf', TfidfTransformer()),\n",
    "  ('sgd', SGDClassifier(loss='modified_huber')),\n",
    "])\n",
    "reddit_classifer.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Accuracy: 0.6611187789234392'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "y_pred = reddit_classifer.predict(X_test)\n",
    "\"Accuracy: \" + str(np.mean(y_pred == y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction Helper Functions\n",
    "\n",
    "Since we preprocessed our post data before classifcation, we need to do the same\n",
    "to any incoming post data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relationship_advice\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'funny': 0.11195594792986989,\n",
       " 'askreddit': 0.17723183877180526,\n",
       " 'art': 0.06273888876347852,\n",
       " 'personalfinance': 0.14012097604544976,\n",
       " 'relationship_advice': 0.30201504562243203}"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preproccessPost(title, text):\n",
    "  noLinks = removeLinks(title + \" \" + text)\n",
    "  tokens = tokenize(noLinks)\n",
    "  return joinTokens(tokens)\n",
    "\n",
    "def predictPrompt(title, text=\"\"):\n",
    "  post = preproccessPost(title, text)\n",
    "  predicted_class = reddit_classifer.predict([post])[0]\n",
    "  return subreddit_classes[predicted_class-1]\n",
    "\n",
    "def predictPromptProbabilities(title, text=\"\", threshold=0.0):\n",
    "  post = preproccessPost(title, text)\n",
    "  prediction = {}\n",
    "  predictions = reddit_classifer.predict_proba([post])[0]\n",
    "  for subreddit_class in subreddit_classes:\n",
    "    if predictions[subreddit_class] > threshold:\n",
    "      subreddit = subreddit_classes[subreddit_class]\n",
    "      prediction[subreddit] = predictions[subreddit_class]\n",
    "  return prediction\n",
    "\n",
    "print(predictPrompt(\"My gf broke up with me, what should I do?\"))\n",
    "predictPromptProbabilities(\"My gf broke up with me, what should I do?\", \"\", 0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flask Server\n",
    "\n",
    "We serve the model and transparency results on a simple Flask server for our frontend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:3000\n",
      " * Running on http://192.168.1.86:3000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [29/Nov/2024 16:13:26] \"GET /predict?title=Soccer!&text= HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [29/Nov/2024 16:13:33] \"GET /predict?title=Soccer2&text= HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [29/Nov/2024 16:13:37] \"GET /predict?title=Soccer%202&text= HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "from flask_cors import CORS\n",
    "\n",
    "app = Flask(__name__)\n",
    "CORS(app)\n",
    "\n",
    "@app.route(\"/predict\")\n",
    "def predictBackend():\n",
    "  title = request.args.get('title')\n",
    "  text = request.args.get('text')\n",
    "  prediction = predictPromptProbabilities(title, text)\n",
    "  return jsonify({'prediction': prediction})\n",
    "\n",
    "app.run(host='0.0.0.0', port=3000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
